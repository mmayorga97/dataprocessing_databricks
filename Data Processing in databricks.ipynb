{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e106ec3-9023-4e8b-8127-dd8cfebabcdf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Data Processing in Databricks, leveraging Pandas, PySpark, and SQL\n",
    "\n",
    "## Instructor: [Marcelino Mayorga Quesada](https://marcelinomayorga.com/)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32081c0f-35bb-43c9-8d01-0d8adbb5dc59",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 1. Summary\n",
    "\n",
    "## 1.1 Data Processing\n",
    "\n",
    "- Data Processing is a series of operations to convert raw data into meaningful information.\n",
    "- Is essential in Data Engineering for Prescriptive, Descriptive, and Exploratory Analysis.\n",
    "- Post Processed data enables: storage to persist transformed data, analysis and machine learning.\n",
    "\n",
    "## 1.2 Operations\n",
    "\n",
    "All of them are applied based on need and objectives:\n",
    "\n",
    "- Cleaning: \n",
    "  - Removing duplicates\n",
    "  - Impute or delete missing values\n",
    "  - Correct errors and inconsistencies\n",
    "- Integration: \n",
    "  - ETL (Extract Transform Load)\n",
    "  - Merge and Join data warehousing\n",
    "  - Augmentation\n",
    "- Transformation:\n",
    "  - Normalization and Standardization\n",
    "  - Aggregation (Summing, Averaging)\n",
    "  - Pivoting tables\n",
    "  - Encoding categorical values\n",
    "- Reduction: \n",
    "  - Dimensionality Reduction: PCA, t-SNE, \n",
    "  - Feature Selection & Extraction\n",
    "  - Sampling\n",
    "  - Compression\n",
    "\n",
    "\n",
    "\n",
    "## 1.3 Databricks\n",
    "\n",
    "- Unified:  \n",
    "  - Data Intelligence Platform \n",
    "  - Collaborative Workspace\n",
    "  - Data Lake Integration with AWS, Azure, GCP.\n",
    "- Open Source Projects:\n",
    "  - Optimized Apache Spark\n",
    "  - MLFlow\n",
    "  - Delta Lake\n",
    "-  Scalable \n",
    "  - Automatic Optimization for storage with great performance\n",
    "\n",
    "## 1.4 Tool Comparison\n",
    "\n",
    "![Tools](https://github.com/mmayorga97/dataprocessing_databricks/blob/main/imgs/tools.png?raw=true)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1319433e-532a-4905-b637-4b86aa77e9b2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "# 2. Lab\n",
    "\n",
    "In this notebook, we will explore how to use Pandas, PySpark, and SQL for data processing within Databricks.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "669804ba-7af9-4926-80b6-c9bf3a89de44",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 2.1 Details \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3bd2178c-64a1-4097-8768-8ce8b8ac3949",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.1.1 Data Workflow\n",
    "\n",
    "![Diagram](https://github.com/mmayorga97/dataprocessing_databricks/blob/main/imgs/diagram.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "528f1d91-1884-447a-a098-f26b8d5b5b99",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "### 2.1.2 Data Source\n",
    "We'll use Large Movie Review Dataset hosted in Hugging Face for this laboratory. Below are the details:\n",
    "\n",
    "| Attribute | Value            |\n",
    "|-----------|------------------|\n",
    "| Source      | HuggingFace|\n",
    "| Dataset      | [imdb](https://huggingface.co/datasets/stanfordnlp/imdb)|\n",
    "| Columns(2) | text,label  |\n",
    "| Purpose | Binary Sentiment Classification|\n",
    "| Rows      | 25000|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "166e84d5-e5f5-4162-a4c3-0060821d27b0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.1.3 Install required libraries\n",
    "\n",
    "Let's install necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b57c8ede-86d5-47c7-a396-0221b3864c47",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d970d984-fdd4-4090-b6d3-f82ce0eaf58f/lib/python3.9/site-packages (2.20.0)\r\nRequirement already satisfied: nltk in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d970d984-fdd4-4090-b6d3-f82ce0eaf58f/lib/python3.9/site-packages (3.8.1)\r\nRequirement already satisfied: aiohttp in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d970d984-fdd4-4090-b6d3-f82ce0eaf58f/lib/python3.9/site-packages (from datasets) (3.9.5)\r\nRequirement already satisfied: tqdm>=4.66.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d970d984-fdd4-4090-b6d3-f82ce0eaf58f/lib/python3.9/site-packages (from datasets) (4.66.4)\r\nRequirement already satisfied: pyyaml>=5.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d970d984-fdd4-4090-b6d3-f82ce0eaf58f/lib/python3.9/site-packages (from datasets) (6.0.1)\r\nRequirement already satisfied: pyarrow-hotfix in /databricks/python3/lib/python3.9/site-packages (from datasets) (0.5)\r\nRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from datasets) (3.9.0)\r\nRequirement already satisfied: requests>=2.32.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d970d984-fdd4-4090-b6d3-f82ce0eaf58f/lib/python3.9/site-packages (from datasets) (2.32.3)\r\nRequirement already satisfied: numpy>=1.17 in /databricks/python3/lib/python3.9/site-packages (from datasets) (1.21.5)\r\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.9/site-packages (from datasets) (1.4.2)\r\nRequirement already satisfied: huggingface-hub>=0.21.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d970d984-fdd4-4090-b6d3-f82ce0eaf58f/lib/python3.9/site-packages (from datasets) (0.23.3)\r\nRequirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d970d984-fdd4-4090-b6d3-f82ce0eaf58f/lib/python3.9/site-packages (from datasets) (2024.5.0)\r\nRequirement already satisfied: xxhash in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d970d984-fdd4-4090-b6d3-f82ce0eaf58f/lib/python3.9/site-packages (from datasets) (3.4.1)\r\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.9/site-packages (from datasets) (21.3)\r\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d970d984-fdd4-4090-b6d3-f82ce0eaf58f/lib/python3.9/site-packages (from datasets) (0.3.8)\r\nRequirement already satisfied: multiprocess in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d970d984-fdd4-4090-b6d3-f82ce0eaf58f/lib/python3.9/site-packages (from datasets) (0.70.16)\r\nRequirement already satisfied: pyarrow>=15.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d970d984-fdd4-4090-b6d3-f82ce0eaf58f/lib/python3.9/site-packages (from datasets) (16.1.0)\r\nRequirement already satisfied: click in /databricks/python3/lib/python3.9/site-packages (from nltk) (8.0.4)\r\nRequirement already satisfied: regex>=2021.8.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d970d984-fdd4-4090-b6d3-f82ce0eaf58f/lib/python3.9/site-packages (from nltk) (2024.5.15)\r\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.9/site-packages (from nltk) (1.1.1)\r\nRequirement already satisfied: frozenlist>=1.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d970d984-fdd4-4090-b6d3-f82ce0eaf58f/lib/python3.9/site-packages (from aiohttp->datasets) (1.4.1)\r\nRequirement already satisfied: yarl<2.0,>=1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d970d984-fdd4-4090-b6d3-f82ce0eaf58f/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.4)\r\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d970d984-fdd4-4090-b6d3-f82ce0eaf58f/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.3)\r\nRequirement already satisfied: aiosignal>=1.1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d970d984-fdd4-4090-b6d3-f82ce0eaf58f/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\r\nRequirement already satisfied: multidict<7.0,>=4.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d970d984-fdd4-4090-b6d3-f82ce0eaf58f/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.5)\r\nRequirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.9/site-packages (from aiohttp->datasets) (21.4.0)\r\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /databricks/python3/lib/python3.9/site-packages (from huggingface-hub>=0.21.2->datasets) (4.1.1)\r\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /databricks/python3/lib/python3.9/site-packages (from packaging->datasets) (3.0.4)\r\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (3.3)\r\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2.0.4)\r\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (1.26.9)\r\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2021.10.8)\r\nRequirement already satisfied: python-dateutil>=2.8.1 in /databricks/python3/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\r\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.9/site-packages (from pandas->datasets) (2021.3)\r\nRequirement already satisfied: six>=1.5 in /databricks/python3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\r\n\u001B[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\r\nYou should consider upgrading via the '/local_disk0/.ephemeral_nfs/envs/pythonEnv-d970d984-fdd4-4090-b6d3-f82ce0eaf58f/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d047da87-95ad-4873-89b6-c91e5f4ae195",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.1.4 Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45e51275-2b04-4fa6-a72c-9eec8ac2833c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import pandas library for data manipulation and analysis\n",
    "import pandas as pd\n",
    "\n",
    "# Import pandas API on Spark\n",
    "import pyspark.pandas as ps\n",
    "\n",
    "# Import functions from PySpark SQL\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Import SparkSession from PySpark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Import SQLContext from PySpark\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "# Import the load_dataset function from the datasets library\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Import the nltk library\n",
    "import nltk\n",
    "\n",
    "# Import the stopwords corpus from nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Import WordNetLemmatizer from nltk.stem for lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Import word_tokenize from nltk.tokenize for tokenizing text\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Import the PorterStemmer from nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Import the RegexpTokenizer from nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# Import the regular expressions module\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3022584-f15d-4682-bec2-1c0a2edd26c9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 2.2 Data Ingest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27a2e3a7-af3d-40f3-a395-e5c2098a8736",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "### 2.2.1 Load Dataset in Memory\n",
    "\n",
    "We'll leverage HuggingFace's datasets to retrieve IMDB dataset. This data is not persisted and will dissappear after the cluster termination or restart.\n",
    "\n",
    "Notice the dataset's type of 'DatasetDict' and the operations are limited.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "427d5879-a677-48ea-84b1-4270f0a5c6bc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[87]: datasets.dataset_dict.DatasetDict"
     ]
    }
   ],
   "source": [
    "# Load the 'imdb' dataset using the load_dataset function\n",
    "dataset = load_dataset('imdb')\n",
    "\n",
    "# Check the type of the loaded dataset\n",
    "type(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2e3d11e-b0a0-4599-965f-a004b13be742",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.2.2 Load dataset into a Pandas Dataframe from Memory\n",
    "\n",
    "We'll load the dataset into a the Pandas dataframe to unlock all the data manipulation features. Pandas is aimed to work on a single node.\n",
    "The data used for this example is considered low volume data.\n",
    "\n",
    "Notice how pd_df's type is Pandas Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "759c9376-4a15-40f2-b44a-03d775e1ed71",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[88]: pandas.core.frame.DataFrame"
     ]
    }
   ],
   "source": [
    "# Convert the 'train' portion of the dataset to a pandas DataFrame\n",
    "pd_df = dataset['train'].to_pandas()\n",
    "\n",
    "# Check the type of the converted pandas DataFrame\n",
    "type(pd_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e489f42f-1af1-499e-98eb-3578f87f1cf8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.2.3 Load Pandas Dataframe to a Pandas-on-Spark Dataframe\n",
    "\n",
    "Now we'll load the Pandas Dataframe into a Pyspark Dataframe, that will allow us continue with familiar interface of Pandas while leveraging the distrubted nature of Spark.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "005fa830-e989-4335-b801-5ecd1b9c3ce4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[89]: pyspark.pandas.frame.DataFrame"
     ]
    }
   ],
   "source": [
    "# Convert the pandas DataFrame pd_df to a PySpark DataFrame ps_df\n",
    "ps_df = ps.from_pandas(pd_df)\n",
    "\n",
    "# Check the type of the converted PySpark DataFrame\n",
    "type(ps_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8a2bc0e-3096-4a0a-b95f-0644672c947f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.5.4 Differences Between Pandas and Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae49bbb8-d98c-446d-854a-b9cf84946ea4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "| Pandas | Pyspark|\n",
    "|-------|-------|\n",
    "|DataFrames|DataFrames|\n",
    "|Low Volume Data| High Volume Data|\n",
    "|Single Computing | Distributed Computing|\n",
    "|Eager Execution| Lazy Evaluation|\n",
    "|N/A| Fault Tolerance|\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf170ec6-45f3-468a-b1be-cbad44435cf0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 2.3 Quick Exploratory Analysis with Pandas API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce0b04fa-a20c-47ae-a250-311774f4bbda",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.3.1 Data's Shape\n",
    "\n",
    "The data contains 25K rows and 2 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fcf36ea-1a08-40d8-b36a-a1a85d24928e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[90]: (25000, 2)"
     ]
    }
   ],
   "source": [
    "# Get the number of columns and rows in the PySpark DataFrame ps_df\n",
    "ps_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "faf652e3-271f-458f-b1b9-acca7ef42d16",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.3.2 Column's Data Types\n",
    "\n",
    "|Column|Type|\n",
    "|------|----|\n",
    "|text|object|\n",
    "|label|int|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b851539f-4490-4ffa-88fe-fef54e9a637d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[91]: text     object\nlabel     int64\ndtype: object"
     ]
    }
   ],
   "source": [
    "# Get the data types of each column in the PySpark DataFrame ps_df\n",
    "ps_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39bd917b-7063-4875-940f-3f4c599d914d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.3.3 Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23007f0c-1629-4abb-9475-05ca88c60818",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.50001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>25000.00000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.50000</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.50001</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.00000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate descriptive statistics for numerical columns in ps_df\n",
    "ps_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e408f47e-9ef8-4dc5-8c75-058c4bd548a9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.3.4. Missing Values\n",
    "\n",
    "No missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6669f3ee-1fd6-470b-b8fc-e82abfb48079",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[93]: text     0\nlabel    0\ndtype: int64"
     ]
    }
   ],
   "source": [
    "# Count the number of null values in each column of the DataFrame\n",
    "ps_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07a5797a-281f-48de-8b7b-a2e0aebfe62d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.3.5 Positive / Negative Review Ratio\n",
    "\n",
    "The dataset is balanced between the two labels: Positive and Negative with 12500k each\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bcaa959-b575-4f6a-b617-692f04cef372",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[94]: 0    12500\n1    12500\nName: label, dtype: int64"
     ]
    }
   ],
   "source": [
    "# Count occurrences of each unique value in the 'label' column\n",
    "ps_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35a535d0-2a1e-47b0-88af-2cb646384b0a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.3.6 Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74d9f4e3-bf79-4e7a-8290-ec12730edd90",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8341</th>\n",
       "      <td>\"Women? They're all scrubbers...!\" &lt;br /&gt;&lt;br /...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8341</th>\n      <td>\"Women? They're all scrubbers...!\" &lt;br /&gt;&lt;br /...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample 0.02% of the DataFrame randomly\n",
    "ps_df.sample(frac=0.0002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "450f68a1-5379-429a-a009-ea800c277b67",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.3.7 A full sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa4ba41a-f936-4a72-8fdb-272d1ba1fd6c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[96]: 'People don\\'t seem to be giving Lensman enough credit where its due. A few issues have been overlooked which are key to understanding the Lensman experience.<br /><br />The Year: For the year it was made in (1984) Lensman features some of the most stunning effects I\\'ve ever seen. As a person who watches a lot of early 80\\'s animation Lensman is unique in it\\'s use of what appears to be computer-generated imagery at a time when computers were extremely primitive. Kim\\'s battle against the geometric cutter pods in the laser maze can be taken as an excellent example of this. Every time I watch that I have to keep repeating to myself that it was 1984 when it was made.<br /><br />The Soundtrack: Lensman has one of the most insane soundtracks that I\\'ve heard, and this mad hysterical beat permeates every corner of the film. Lensman borrowed heavily on two western mistakes and managed to somewhat deal with the first one - the need to fill in every second of silence in a film with music and the need for a heroine. While the music is attuned well and galvanizes scenes such as the motorcycle battle in the Thionite Factory on Radelyx, the heroine theme fails due to the sheer annoyance value of Chris. It\\'s interesting to note that the constant music thwarted my attempts at noise removal when I was archiving lensman over from analog tape to digital format - since there wasn\\'t a single second of silence available to use as a reference point.<br /><br />Western Influences: Helmut - sounds like \"helmet\" and has roughly the same voice as Darth Vader. Clarissa Fairborn - has the same hairstyle as the princess of SW and her name sounds suspiciously similar to Marissa Fairborn of Transformers. Takes over Han Solos role by flying the ship and having some technical expertise. Buzzkirk - a definite improvement on Chewbaka. The lens - a nice concrete copy of the force that comes across less as a chance to preach Christianity at the audience than in the original SW. While the force relied on belief far more than concentration, the lens is a pure concentration tool. Theoretically, anyone could wield the lens. The lens is far more limited than the Force - being purely a defensive/offensive weapon.<br /><br />Technology: The boskone alliance have interesting meatball sponge ships. They look like stormtroopers only with red uniforms instead of white. The idea of a DNA weapon was nice if only it had been developed. The Galactic Alliance looked like Starblazers (or whatever it was called - that 60\\'s series where they were battling the Xylons). There weren\\'t enough ship to ship battles for me - this is much improved upon in the second Lensman film.<br /><br />Finally a note on Worzel. This character is a unique and very interesting character-design who fortunately continues on to the second film.<br /><br />'"
     ]
    }
   ],
   "source": [
    "# Example of text from a review\n",
    "ps_df['text'][17370]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c221fd3c-a437-4f5b-ada9-2a01a895fd41",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.3.8 Data Summary \n",
    "\n",
    "After this quick exploratory data analysis we can conclude:\n",
    "  - Dataset only handles 2 columns: \n",
    "    - one text as 'review' of the movie.\n",
    "    - label to distinguish between positive and negative review.\n",
    "  - There are no missing values.\n",
    "  - There are no no duplicate values.\n",
    "  - Both Labels (Positive & Negative) are balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb49e37e-0f1d-4758-af52-3941e085429e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 2.4 Data Processing for NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46dc0f7f-3cbc-46f0-a9e3-64245eb3a72c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.4.1 Remove Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fa71ff4-fc2d-40fb-ae48-3f8bdaa2c0d7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>I rented I AM CURIOUSYELLOW from my video stor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "      <td>I Am Curious Yellow is a risible and pretentio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>This film was probably inspired by Godards Mas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "      <td>Oh brotherafter hearing about this ridiculous ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>cleaned_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n      <td>0</td>\n      <td>I rented I AM CURIOUSYELLOW from my video stor...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n      <td>0</td>\n      <td>I Am Curious Yellow is a risible and pretentio...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>If only to avoid making this type of film in t...</td>\n      <td>0</td>\n      <td>If only to avoid making this type of film in t...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>This film was probably inspired by Godard's Ma...</td>\n      <td>0</td>\n      <td>This film was probably inspired by Godards Mas...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Oh, brother...after hearing about this ridicul...</td>\n      <td>0</td>\n      <td>Oh brotherafter hearing about this ridiculous ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove non-alphabetic characters from 'text' and update 'cleaned_text' column\n",
    "ps_df['cleaned_text'] = ps_df['text'].apply(lambda x: re.sub('[^a-zA-Z\\s]', '', x))\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "ps_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdb177c3-1658-4dfc-9dad-54aa6cf7af57",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.4.2 Convert to lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8028baf7-5554-4263-80b5-8e6e051fd55a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>i rented i am curiousyellow from my video stor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "      <td>i am curious yellow is a risible and pretentio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "      <td>if only to avoid making this type of film in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>this film was probably inspired by godards mas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "      <td>oh brotherafter hearing about this ridiculous ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>cleaned_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n      <td>0</td>\n      <td>i rented i am curiousyellow from my video stor...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n      <td>0</td>\n      <td>i am curious yellow is a risible and pretentio...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>If only to avoid making this type of film in t...</td>\n      <td>0</td>\n      <td>if only to avoid making this type of film in t...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>This film was probably inspired by Godard's Ma...</td>\n      <td>0</td>\n      <td>this film was probably inspired by godards mas...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Oh, brother...after hearing about this ridicul...</td>\n      <td>0</td>\n      <td>oh brotherafter hearing about this ridiculous ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert text in 'cleaned_text' column to lowercase\n",
    "ps_df['cleaned_text'] = ps_df['cleaned_text'].str.lower()\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "ps_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "055f05e9-df8e-497f-9241-93f8917f5fee",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.4.3 Remove Stop Words with nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50959101-80fe-4e2c-9372-d518ed609644",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>rented curiousyellow video store controversy s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "      <td>curious yellow risible pretentious steaming pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "      <td>avoid making type film future film interesting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>film probably inspired godards masculin fminin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "      <td>oh brotherafter hearing ridiculous film umptee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>cleaned_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n      <td>0</td>\n      <td>rented curiousyellow video store controversy s...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n      <td>0</td>\n      <td>curious yellow risible pretentious steaming pi...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>If only to avoid making this type of film in t...</td>\n      <td>0</td>\n      <td>avoid making type film future film interesting...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>This film was probably inspired by Godard's Ma...</td>\n      <td>0</td>\n      <td>film probably inspired godards masculin fminin...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Oh, brother...after hearing about this ridicul...</td>\n      <td>0</td>\n      <td>oh brotherafter hearing ridiculous film umptee...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ensure you have the NLTK data downloaded\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Assuming ps_df is your DataFrame and 'cleaned_text' is the column with text data\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "# Apply the function to the 'cleaned_text' column\n",
    "ps_df['cleaned_text'] = ps_df['cleaned_text'].apply(remove_stopwords)\n",
    "\n",
    "# Show results\n",
    "ps_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db354238-3394-40e9-a54c-c019a3728026",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.4.4 Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e9e5668-f4d6-468a-96a8-4a7dd43b026e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>rented curiousyellow video store controversy s...</td>\n",
       "      <td>[rented, curiousyellow, video, store, controve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "      <td>curious yellow risible pretentious steaming pi...</td>\n",
       "      <td>[curious, yellow, risible, pretentious, steami...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "      <td>avoid making type film future film interesting...</td>\n",
       "      <td>[avoid, making, type, film, future, film, inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>film probably inspired godards masculin fminin...</td>\n",
       "      <td>[film, probably, inspired, godards, masculin, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "      <td>oh brotherafter hearing ridiculous film umptee...</td>\n",
       "      <td>[oh, brotherafter, hearing, ridiculous, film, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>cleaned_text</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n      <td>0</td>\n      <td>rented curiousyellow video store controversy s...</td>\n      <td>[rented, curiousyellow, video, store, controve...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n      <td>0</td>\n      <td>curious yellow risible pretentious steaming pi...</td>\n      <td>[curious, yellow, risible, pretentious, steami...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>If only to avoid making this type of film in t...</td>\n      <td>0</td>\n      <td>avoid making type film future film interesting...</td>\n      <td>[avoid, making, type, film, future, film, inte...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>This film was probably inspired by Godard's Ma...</td>\n      <td>0</td>\n      <td>film probably inspired godards masculin fminin...</td>\n      <td>[film, probably, inspired, godards, masculin, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Oh, brother...after hearing about this ridicul...</td>\n      <td>0</td>\n      <td>oh brotherafter hearing ridiculous film umptee...</td>\n      <td>[oh, brotherafter, hearing, ridiculous, film, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize tokenizer to match words (alphanumeric characters)\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# Tokenize cleaned text and create a new column 'tokens'\n",
    "ps_df['tokens'] = ps_df['cleaned_text'].apply(lambda x: tokenizer.tokenize(x))\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "ps_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bba4c001-cda4-483f-a4e2-03d7d684fac7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.4.5  Stemming\n",
    "- Stemming is a process in Natural Language Processing (NLP) that reduces words to their root form or stem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e2a83b8-f5d6-4db4-b6ce-9e2cc1f5b837",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>rented curiousyellow video store controversy s...</td>\n",
       "      <td>[rented, curiousyellow, video, store, controve...</td>\n",
       "      <td>[rent, curiousyellow, video, store, controvers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "      <td>curious yellow risible pretentious steaming pi...</td>\n",
       "      <td>[curious, yellow, risible, pretentious, steami...</td>\n",
       "      <td>[curiou, yellow, risibl, pretenti, steam, pile...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "      <td>avoid making type film future film interesting...</td>\n",
       "      <td>[avoid, making, type, film, future, film, inte...</td>\n",
       "      <td>[avoid, make, type, film, futur, film, interes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>film probably inspired godards masculin fminin...</td>\n",
       "      <td>[film, probably, inspired, godards, masculin, ...</td>\n",
       "      <td>[film, probabl, inspir, godard, masculin, fmin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "      <td>oh brotherafter hearing ridiculous film umptee...</td>\n",
       "      <td>[oh, brotherafter, hearing, ridiculous, film, ...</td>\n",
       "      <td>[oh, brotheraft, hear, ridicul, film, umpteen,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>cleaned_text</th>\n      <th>tokens</th>\n      <th>stemmed_tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n      <td>0</td>\n      <td>rented curiousyellow video store controversy s...</td>\n      <td>[rented, curiousyellow, video, store, controve...</td>\n      <td>[rent, curiousyellow, video, store, controvers...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n      <td>0</td>\n      <td>curious yellow risible pretentious steaming pi...</td>\n      <td>[curious, yellow, risible, pretentious, steami...</td>\n      <td>[curiou, yellow, risibl, pretenti, steam, pile...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>If only to avoid making this type of film in t...</td>\n      <td>0</td>\n      <td>avoid making type film future film interesting...</td>\n      <td>[avoid, making, type, film, future, film, inte...</td>\n      <td>[avoid, make, type, film, futur, film, interes...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>This film was probably inspired by Godard's Ma...</td>\n      <td>0</td>\n      <td>film probably inspired godards masculin fminin...</td>\n      <td>[film, probably, inspired, godards, masculin, ...</td>\n      <td>[film, probabl, inspir, godard, masculin, fmin...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Oh, brother...after hearing about this ridicul...</td>\n      <td>0</td>\n      <td>oh brotherafter hearing ridiculous film umptee...</td>\n      <td>[oh, brotherafter, hearing, ridiculous, film, ...</td>\n      <td>[oh, brotheraft, hear, ridicul, film, umpteen,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Stem each token in the 'tokens' column and create a new column 'stemmed_tokens'\n",
    "ps_df['stemmed_tokens'] = ps_df['tokens'].apply(lambda x: [stemmer.stem(token) for token in x])\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "ps_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c93312df-c82f-4722-88a2-278fe2065b55",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.4.6  Lemmatization\n",
    "\n",
    "- Lemmatization is a more sophisticated technique than stemming. It aims to reduce words to their base or dictionary form, known as the lemma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "549c1e83-443c-468a-b67e-58ee303c5b0a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>rented curiousyellow video store controversy s...</td>\n",
       "      <td>[rented, curiousyellow, video, store, controve...</td>\n",
       "      <td>[rent, curiousyellow, video, store, controvers...</td>\n",
       "      <td>[rented, curiousyellow, video, store, controve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "      <td>curious yellow risible pretentious steaming pi...</td>\n",
       "      <td>[curious, yellow, risible, pretentious, steami...</td>\n",
       "      <td>[curiou, yellow, risibl, pretenti, steam, pile...</td>\n",
       "      <td>[curious, yellow, risible, pretentious, steami...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "      <td>avoid making type film future film interesting...</td>\n",
       "      <td>[avoid, making, type, film, future, film, inte...</td>\n",
       "      <td>[avoid, make, type, film, futur, film, interes...</td>\n",
       "      <td>[avoid, making, type, film, future, film, inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>film probably inspired godards masculin fminin...</td>\n",
       "      <td>[film, probably, inspired, godards, masculin, ...</td>\n",
       "      <td>[film, probabl, inspir, godard, masculin, fmin...</td>\n",
       "      <td>[film, probably, inspired, godard, masculin, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "      <td>oh brotherafter hearing ridiculous film umptee...</td>\n",
       "      <td>[oh, brotherafter, hearing, ridiculous, film, ...</td>\n",
       "      <td>[oh, brotheraft, hear, ridicul, film, umpteen,...</td>\n",
       "      <td>[oh, brotherafter, hearing, ridiculous, film, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>cleaned_text</th>\n      <th>tokens</th>\n      <th>stemmed_tokens</th>\n      <th>lemmatized_tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n      <td>0</td>\n      <td>rented curiousyellow video store controversy s...</td>\n      <td>[rented, curiousyellow, video, store, controve...</td>\n      <td>[rent, curiousyellow, video, store, controvers...</td>\n      <td>[rented, curiousyellow, video, store, controve...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n      <td>0</td>\n      <td>curious yellow risible pretentious steaming pi...</td>\n      <td>[curious, yellow, risible, pretentious, steami...</td>\n      <td>[curiou, yellow, risibl, pretenti, steam, pile...</td>\n      <td>[curious, yellow, risible, pretentious, steami...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>If only to avoid making this type of film in t...</td>\n      <td>0</td>\n      <td>avoid making type film future film interesting...</td>\n      <td>[avoid, making, type, film, future, film, inte...</td>\n      <td>[avoid, make, type, film, futur, film, interes...</td>\n      <td>[avoid, making, type, film, future, film, inte...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>This film was probably inspired by Godard's Ma...</td>\n      <td>0</td>\n      <td>film probably inspired godards masculin fminin...</td>\n      <td>[film, probably, inspired, godards, masculin, ...</td>\n      <td>[film, probabl, inspir, godard, masculin, fmin...</td>\n      <td>[film, probably, inspired, godard, masculin, f...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Oh, brother...after hearing about this ridicul...</td>\n      <td>0</td>\n      <td>oh brotherafter hearing ridiculous film umptee...</td>\n      <td>[oh, brotherafter, hearing, ridiculous, film, ...</td>\n      <td>[oh, brotheraft, hear, ridicul, film, umpteen,...</td>\n      <td>[oh, brotherafter, hearing, ridiculous, film, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ensure you have the NLTK data downloaded\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Assuming ps_df is your DataFrame and 'tokens' is the column with texts\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_tokens(tokens):\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "# Apply lemmatization to each row in the 'tokens' column\n",
    "ps_df['lemmatized_tokens'] = ps_df['tokens'].apply(lemmatize_tokens)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "ps_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4234ff8-4916-4825-9225-aaf31a0a1e0d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.4.7 Get count of the contents for columns\n",
    "\n",
    "- text\n",
    "- cleaned_text\n",
    "- tokens\n",
    "- stemmed_tokens\n",
    "- lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9552afb-d1f0-4b37-a914-e5f8b1c87439",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "      <th>review_length</th>\n",
       "      <th>cleaned_text_length</th>\n",
       "      <th>tokens_length</th>\n",
       "      <th>stemmed_tokens_length</th>\n",
       "      <th>lemmatized_tokens_length</th>\n",
       "      <th>text_count</th>\n",
       "      <th>cleaned_text_count</th>\n",
       "      <th>tokens_count</th>\n",
       "      <th>stemmed_tokens_count</th>\n",
       "      <th>lemmatized_tokens_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>rented curiousyellow video store controversy s...</td>\n",
       "      <td>[rented, curiousyellow, video, store, controve...</td>\n",
       "      <td>[rent, curiousyellow, video, store, controvers...</td>\n",
       "      <td>[rented, curiousyellow, video, store, controve...</td>\n",
       "      <td>1640</td>\n",
       "      <td>1061</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>1640</td>\n",
       "      <td>1061</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "      <td>curious yellow risible pretentious steaming pi...</td>\n",
       "      <td>[curious, yellow, risible, pretentious, steami...</td>\n",
       "      <td>[curiou, yellow, risibl, pretenti, steam, pile...</td>\n",
       "      <td>[curious, yellow, risible, pretentious, steami...</td>\n",
       "      <td>1294</td>\n",
       "      <td>871</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>1294</td>\n",
       "      <td>871</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "      <td>avoid making type film future film interesting...</td>\n",
       "      <td>[avoid, making, type, film, future, film, inte...</td>\n",
       "      <td>[avoid, make, type, film, futur, film, interes...</td>\n",
       "      <td>[avoid, making, type, film, future, film, inte...</td>\n",
       "      <td>528</td>\n",
       "      <td>346</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>528</td>\n",
       "      <td>346</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>film probably inspired godards masculin fminin...</td>\n",
       "      <td>[film, probably, inspired, godards, masculin, ...</td>\n",
       "      <td>[film, probabl, inspir, godard, masculin, fmin...</td>\n",
       "      <td>[film, probably, inspired, godard, masculin, f...</td>\n",
       "      <td>706</td>\n",
       "      <td>428</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>706</td>\n",
       "      <td>428</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "      <td>oh brotherafter hearing ridiculous film umptee...</td>\n",
       "      <td>[oh, brotherafter, hearing, ridiculous, film, ...</td>\n",
       "      <td>[oh, brotheraft, hear, ridicul, film, umpteen,...</td>\n",
       "      <td>[oh, brotherafter, hearing, ridiculous, film, ...</td>\n",
       "      <td>1814</td>\n",
       "      <td>1185</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>1814</td>\n",
       "      <td>1185</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>cleaned_text</th>\n      <th>tokens</th>\n      <th>stemmed_tokens</th>\n      <th>lemmatized_tokens</th>\n      <th>review_length</th>\n      <th>cleaned_text_length</th>\n      <th>tokens_length</th>\n      <th>stemmed_tokens_length</th>\n      <th>lemmatized_tokens_length</th>\n      <th>text_count</th>\n      <th>cleaned_text_count</th>\n      <th>tokens_count</th>\n      <th>stemmed_tokens_count</th>\n      <th>lemmatized_tokens_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n      <td>0</td>\n      <td>rented curiousyellow video store controversy s...</td>\n      <td>[rented, curiousyellow, video, store, controve...</td>\n      <td>[rent, curiousyellow, video, store, controvers...</td>\n      <td>[rented, curiousyellow, video, store, controve...</td>\n      <td>1640</td>\n      <td>1061</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n      <td>1640</td>\n      <td>1061</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n      <td>0</td>\n      <td>curious yellow risible pretentious steaming pi...</td>\n      <td>[curious, yellow, risible, pretentious, steami...</td>\n      <td>[curiou, yellow, risibl, pretenti, steam, pile...</td>\n      <td>[curious, yellow, risible, pretentious, steami...</td>\n      <td>1294</td>\n      <td>871</td>\n      <td>120</td>\n      <td>120</td>\n      <td>120</td>\n      <td>1294</td>\n      <td>871</td>\n      <td>120</td>\n      <td>120</td>\n      <td>120</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>If only to avoid making this type of film in t...</td>\n      <td>0</td>\n      <td>avoid making type film future film interesting...</td>\n      <td>[avoid, making, type, film, future, film, inte...</td>\n      <td>[avoid, make, type, film, futur, film, interes...</td>\n      <td>[avoid, making, type, film, future, film, inte...</td>\n      <td>528</td>\n      <td>346</td>\n      <td>52</td>\n      <td>52</td>\n      <td>52</td>\n      <td>528</td>\n      <td>346</td>\n      <td>52</td>\n      <td>52</td>\n      <td>52</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>This film was probably inspired by Godard's Ma...</td>\n      <td>0</td>\n      <td>film probably inspired godards masculin fminin...</td>\n      <td>[film, probably, inspired, godards, masculin, ...</td>\n      <td>[film, probabl, inspir, godard, masculin, fmin...</td>\n      <td>[film, probably, inspired, godard, masculin, f...</td>\n      <td>706</td>\n      <td>428</td>\n      <td>58</td>\n      <td>58</td>\n      <td>58</td>\n      <td>706</td>\n      <td>428</td>\n      <td>58</td>\n      <td>58</td>\n      <td>58</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Oh, brother...after hearing about this ridicul...</td>\n      <td>0</td>\n      <td>oh brotherafter hearing ridiculous film umptee...</td>\n      <td>[oh, brotherafter, hearing, ridiculous, film, ...</td>\n      <td>[oh, brotheraft, hear, ridicul, film, umpteen,...</td>\n      <td>[oh, brotherafter, hearing, ridiculous, film, ...</td>\n      <td>1814</td>\n      <td>1185</td>\n      <td>172</td>\n      <td>172</td>\n      <td>172</td>\n      <td>1814</td>\n      <td>1185</td>\n      <td>172</td>\n      <td>172</td>\n      <td>172</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate count of each review in characters and create 'review_length' column\n",
    "ps_df['text_count'] = ps_df['text'].apply(len)\n",
    "\n",
    "# Calculate count of cleaned text in characters and create 'cleaned_text_length' column\n",
    "ps_df['cleaned_text_count'] = ps_df['cleaned_text'].apply(len)\n",
    "\n",
    "# Calculate number of tokens in each review and create 'tokens_length' column\n",
    "ps_df['tokens_count'] = ps_df['tokens'].apply(len)\n",
    "\n",
    "# Calculate number of stemmed tokens in each review and create 'stemmed_tokens_length' column\n",
    "ps_df['stemmed_tokens_count'] = ps_df['stemmed_tokens'].apply(len)\n",
    "\n",
    "# Calculate number of stemmed tokens in each review and create 'stemmed_tokens_length' column\n",
    "ps_df['lemmatized_tokens_count'] = ps_df['lemmatized_tokens'].apply(len)\n",
    "\n",
    "# Display the first few rows of the updated DataFrame\n",
    "ps_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "845c8adf-d606-4cef-b51f-753ef4b42e8e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 2.5. Create SQL Table with the processed data using Spark Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40774716-663f-454e-8ef2-5b54cd70c07f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.5.1 Load Pandas-on-Spark Dataframe to a Spark Dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3bd8241-7cd9-4c7a-993d-7d5bd44e9676",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[119]: pyspark.sql.dataframe.DataFrame"
     ]
    }
   ],
   "source": [
    "# Convert the PySpark DataFrame ps_df to a Spark DataFrame ps_spark_df\n",
    "ps_spark_df = ps_df.to_spark()\n",
    "\n",
    "# Check the type of the converted Spark DataFrame\n",
    "type(ps_spark_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fa8d360-a032-4c4e-a0c2-a193a7bee0b7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.5.2 Create SQL Table from Spark Dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29eaedb4-4cd4-4f6f-8c79-bdceb0525549",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert the PySpark DataFrame ps_df to a Spark DataFrame and create a temporary view\n",
    "# named \"imdb_prepared\" in the Spark session\n",
    "ps_df.to_spark().createOrReplaceTempView(\"imdb_prepared\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b710ccf-5d4f-43c1-ac81-75079ac7f610",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.5.3. Query SQL Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96d47ce9-d8f0-4525-8f5e-4dde6b1aa860",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>text</th><th>label</th><th>cleaned_text</th><th>tokens</th><th>stemmed_tokens</th><th>lemmatized_tokens</th><th>review_length</th><th>cleaned_text_length</th><th>tokens_length</th><th>stemmed_tokens_length</th><th>lemmatized_tokens_length</th><th>text_count</th><th>cleaned_text_count</th><th>tokens_count</th><th>stemmed_tokens_count</th><th>lemmatized_tokens_count</th></tr></thead><tbody><tr><td>My interest in Dorothy Stratten caused me to purchase this video. Although it had great actors/actresses, there were just too many subplots going on to retain interest. Plus it just wasn't that interesting. Dialogue was stiff and confusing and the story just flipped around too much to be believable. I was pretty disappointed in what I believe was one of Audrey Hepburn's last movies. I'll always love John Ritter best in slapstick. He was just too pathetic here.</td><td>0</td><td>interest dorothy stratten caused purchase video although great actorsactresses many subplots going retain interest plus wasnt interesting dialogue stiff confusing story flipped around much believable pretty disappointed believe one audrey hepburns last movies ill always love john ritter best slapstick pathetic</td><td>List(interest, dorothy, stratten, caused, purchase, video, although, great, actorsactresses, many, subplots, going, retain, interest, plus, wasnt, interesting, dialogue, stiff, confusing, story, flipped, around, much, believable, pretty, disappointed, believe, one, audrey, hepburns, last, movies, ill, always, love, john, ritter, best, slapstick, pathetic)</td><td>List(interest, dorothi, stratten, caus, purchas, video, although, great, actorsactress, mani, subplot, go, retain, interest, plu, wasnt, interest, dialogu, stiff, confus, stori, flip, around, much, believ, pretti, disappoint, believ, one, audrey, hepburn, last, movi, ill, alway, love, john, ritter, best, slapstick, pathet)</td><td>List(interest, dorothy, stratten, caused, purchase, video, although, great, actorsactresses, many, subplots, going, retain, interest, plus, wasnt, interesting, dialogue, stiff, confusing, story, flipped, around, much, believable, pretty, disappointed, believe, one, audrey, hepburn, last, movie, ill, always, love, john, ritter, best, slapstick, pathetic)</td><td>464</td><td>311</td><td>41</td><td>41</td><td>41</td><td>464</td><td>311</td><td>41</td><td>41</td><td>41</td></tr><tr><td>I think I will make a movie next weekend. Oh wait, I'm working..oh I'm sure I can fit it in. It looks like whoever made this film fit it in. I hope the makers of this crap have day jobs because this film sucked!!! It looks like someones home movie and I don't think more than $100 was spent making it!!! Total crap!!! Who let's this stuff be released?!?!?!</td><td>0</td><td>think make movie next weekend oh wait im workingoh im sure fit looks like whoever made film fit hope makers crap day jobs film sucked looks like someones home movie dont think spent making total crap lets stuff released</td><td>List(think, make, movie, next, weekend, oh, wait, im, workingoh, im, sure, fit, looks, like, whoever, made, film, fit, hope, makers, crap, day, jobs, film, sucked, looks, like, someones, home, movie, dont, think, spent, making, total, crap, lets, stuff, released)</td><td>List(think, make, movi, next, weekend, oh, wait, im, workingoh, im, sure, fit, look, like, whoever, made, film, fit, hope, maker, crap, day, job, film, suck, look, like, someon, home, movi, dont, think, spent, make, total, crap, let, stuff, releas)</td><td>List(think, make, movie, next, weekend, oh, wait, im, workingoh, im, sure, fit, look, like, whoever, made, film, fit, hope, maker, crap, day, job, film, sucked, look, like, someone, home, movie, dont, think, spent, making, total, crap, let, stuff, released)</td><td>356</td><td>219</td><td>39</td><td>39</td><td>39</td><td>356</td><td>219</td><td>39</td><td>39</td><td>39</td></tr><tr><td>Ned aKelly is such an important story to Australians but this movie is awful. It's an Australian story yet it seems like it was set in America. Also Ned was an Australian yet he has an Irish accent...it is the worst film I have seen in a long time</td><td>0</td><td>ned akelly important story australians movie awful australian story yet seems like set america also ned australian yet irish accentit worst film seen long time</td><td>List(ned, akelly, important, story, australians, movie, awful, australian, story, yet, seems, like, set, america, also, ned, australian, yet, irish, accentit, worst, film, seen, long, time)</td><td>List(ned, akelli, import, stori, australian, movi, aw, australian, stori, yet, seem, like, set, america, also, ned, australian, yet, irish, accentit, worst, film, seen, long, time)</td><td>List(ned, akelly, important, story, australian, movie, awful, australian, story, yet, seems, like, set, america, also, ned, australian, yet, irish, accentit, worst, film, seen, long, time)</td><td>247</td><td>159</td><td>25</td><td>25</td><td>25</td><td>247</td><td>159</td><td>25</td><td>25</td><td>25</td></tr><tr><td>Protocol is an implausible movie whose only saving grace is that it stars Goldie Hawn along with a good cast of supporting actors. The story revolves around a ditzy cocktail waitress who becomes famous after inadvertently saving the life of an Arab dignitary. The story goes downhill halfway through the movie and Goldie's charm just doesn't save this movie. Unless you are a Goldie Hawn fan don't go out of your way to see this film.</td><td>0</td><td>protocol implausible movie whose saving grace stars goldie hawn along good cast supporting actors story revolves around ditzy cocktail waitress becomes famous inadvertently saving life arab dignitary story goes downhill halfway movie goldies charm doesnt save movie unless goldie hawn fan dont go way see film</td><td>List(protocol, implausible, movie, whose, saving, grace, stars, goldie, hawn, along, good, cast, supporting, actors, story, revolves, around, ditzy, cocktail, waitress, becomes, famous, inadvertently, saving, life, arab, dignitary, story, goes, downhill, halfway, movie, goldies, charm, doesnt, save, movie, unless, goldie, hawn, fan, dont, go, way, see, film)</td><td>List(protocol, implaus, movi, whose, save, grace, star, goldi, hawn, along, good, cast, support, actor, stori, revolv, around, ditzi, cocktail, waitress, becom, famou, inadvert, save, life, arab, dignitari, stori, goe, downhil, halfway, movi, goldi, charm, doesnt, save, movi, unless, goldi, hawn, fan, dont, go, way, see, film)</td><td>List(protocol, implausible, movie, whose, saving, grace, star, goldie, hawn, along, good, cast, supporting, actor, story, revolves, around, ditzy, cocktail, waitress, becomes, famous, inadvertently, saving, life, arab, dignitary, story, go, downhill, halfway, movie, goldies, charm, doesnt, save, movie, unless, goldie, hawn, fan, dont, go, way, see, film)</td><td>434</td><td>309</td><td>46</td><td>46</td><td>46</td><td>434</td><td>309</td><td>46</td><td>46</td><td>46</td></tr><tr><td>Outlandish premise that rates low on plausibility and unfortunately also struggles feebly to raise laughs or interest. Only Hawn's well-known charm allows it to skate by on very thin ice. Goldie's gotta be a contender for an actress who's done so much in her career with very little quality material at her disposal...<br /><br /></td><td>0</td><td>outlandish premise rates low plausibility unfortunately also struggles feebly raise laughs interest hawns wellknown charm allows skate thin ice goldies gotta contender actress whos done much career little quality material disposalbr br</td><td>List(outlandish, premise, rates, low, plausibility, unfortunately, also, struggles, feebly, raise, laughs, interest, hawns, wellknown, charm, allows, skate, thin, ice, goldies, gotta, contender, actress, whos, done, much, career, little, quality, material, disposalbr, br)</td><td>List(outlandish, premis, rate, low, plausibl, unfortun, also, struggl, feebli, rais, laugh, interest, hawn, wellknown, charm, allow, skate, thin, ice, goldi, gotta, contend, actress, who, done, much, career, littl, qualiti, materi, disposalbr, br)</td><td>List(outlandish, premise, rate, low, plausibility, unfortunately, also, struggle, feebly, raise, laugh, interest, hawns, wellknown, charm, allows, skate, thin, ice, goldies, gotta, contender, actress, who, done, much, career, little, quality, material, disposalbr, br)</td><td>330</td><td>235</td><td>32</td><td>32</td><td>32</td><td>330</td><td>235</td><td>32</td><td>32</td><td>32</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "My interest in Dorothy Stratten caused me to purchase this video. Although it had great actors/actresses, there were just too many subplots going on to retain interest. Plus it just wasn't that interesting. Dialogue was stiff and confusing and the story just flipped around too much to be believable. I was pretty disappointed in what I believe was one of Audrey Hepburn's last movies. I'll always love John Ritter best in slapstick. He was just too pathetic here.",
         0,
         "interest dorothy stratten caused purchase video although great actorsactresses many subplots going retain interest plus wasnt interesting dialogue stiff confusing story flipped around much believable pretty disappointed believe one audrey hepburns last movies ill always love john ritter best slapstick pathetic",
         [
          "interest",
          "dorothy",
          "stratten",
          "caused",
          "purchase",
          "video",
          "although",
          "great",
          "actorsactresses",
          "many",
          "subplots",
          "going",
          "retain",
          "interest",
          "plus",
          "wasnt",
          "interesting",
          "dialogue",
          "stiff",
          "confusing",
          "story",
          "flipped",
          "around",
          "much",
          "believable",
          "pretty",
          "disappointed",
          "believe",
          "one",
          "audrey",
          "hepburns",
          "last",
          "movies",
          "ill",
          "always",
          "love",
          "john",
          "ritter",
          "best",
          "slapstick",
          "pathetic"
         ],
         [
          "interest",
          "dorothi",
          "stratten",
          "caus",
          "purchas",
          "video",
          "although",
          "great",
          "actorsactress",
          "mani",
          "subplot",
          "go",
          "retain",
          "interest",
          "plu",
          "wasnt",
          "interest",
          "dialogu",
          "stiff",
          "confus",
          "stori",
          "flip",
          "around",
          "much",
          "believ",
          "pretti",
          "disappoint",
          "believ",
          "one",
          "audrey",
          "hepburn",
          "last",
          "movi",
          "ill",
          "alway",
          "love",
          "john",
          "ritter",
          "best",
          "slapstick",
          "pathet"
         ],
         [
          "interest",
          "dorothy",
          "stratten",
          "caused",
          "purchase",
          "video",
          "although",
          "great",
          "actorsactresses",
          "many",
          "subplots",
          "going",
          "retain",
          "interest",
          "plus",
          "wasnt",
          "interesting",
          "dialogue",
          "stiff",
          "confusing",
          "story",
          "flipped",
          "around",
          "much",
          "believable",
          "pretty",
          "disappointed",
          "believe",
          "one",
          "audrey",
          "hepburn",
          "last",
          "movie",
          "ill",
          "always",
          "love",
          "john",
          "ritter",
          "best",
          "slapstick",
          "pathetic"
         ],
         464,
         311,
         41,
         41,
         41,
         464,
         311,
         41,
         41,
         41
        ],
        [
         "I think I will make a movie next weekend. Oh wait, I'm working..oh I'm sure I can fit it in. It looks like whoever made this film fit it in. I hope the makers of this crap have day jobs because this film sucked!!! It looks like someones home movie and I don't think more than $100 was spent making it!!! Total crap!!! Who let's this stuff be released?!?!?!",
         0,
         "think make movie next weekend oh wait im workingoh im sure fit looks like whoever made film fit hope makers crap day jobs film sucked looks like someones home movie dont think spent making total crap lets stuff released",
         [
          "think",
          "make",
          "movie",
          "next",
          "weekend",
          "oh",
          "wait",
          "im",
          "workingoh",
          "im",
          "sure",
          "fit",
          "looks",
          "like",
          "whoever",
          "made",
          "film",
          "fit",
          "hope",
          "makers",
          "crap",
          "day",
          "jobs",
          "film",
          "sucked",
          "looks",
          "like",
          "someones",
          "home",
          "movie",
          "dont",
          "think",
          "spent",
          "making",
          "total",
          "crap",
          "lets",
          "stuff",
          "released"
         ],
         [
          "think",
          "make",
          "movi",
          "next",
          "weekend",
          "oh",
          "wait",
          "im",
          "workingoh",
          "im",
          "sure",
          "fit",
          "look",
          "like",
          "whoever",
          "made",
          "film",
          "fit",
          "hope",
          "maker",
          "crap",
          "day",
          "job",
          "film",
          "suck",
          "look",
          "like",
          "someon",
          "home",
          "movi",
          "dont",
          "think",
          "spent",
          "make",
          "total",
          "crap",
          "let",
          "stuff",
          "releas"
         ],
         [
          "think",
          "make",
          "movie",
          "next",
          "weekend",
          "oh",
          "wait",
          "im",
          "workingoh",
          "im",
          "sure",
          "fit",
          "look",
          "like",
          "whoever",
          "made",
          "film",
          "fit",
          "hope",
          "maker",
          "crap",
          "day",
          "job",
          "film",
          "sucked",
          "look",
          "like",
          "someone",
          "home",
          "movie",
          "dont",
          "think",
          "spent",
          "making",
          "total",
          "crap",
          "let",
          "stuff",
          "released"
         ],
         356,
         219,
         39,
         39,
         39,
         356,
         219,
         39,
         39,
         39
        ],
        [
         "Ned aKelly is such an important story to Australians but this movie is awful. It's an Australian story yet it seems like it was set in America. Also Ned was an Australian yet he has an Irish accent...it is the worst film I have seen in a long time",
         0,
         "ned akelly important story australians movie awful australian story yet seems like set america also ned australian yet irish accentit worst film seen long time",
         [
          "ned",
          "akelly",
          "important",
          "story",
          "australians",
          "movie",
          "awful",
          "australian",
          "story",
          "yet",
          "seems",
          "like",
          "set",
          "america",
          "also",
          "ned",
          "australian",
          "yet",
          "irish",
          "accentit",
          "worst",
          "film",
          "seen",
          "long",
          "time"
         ],
         [
          "ned",
          "akelli",
          "import",
          "stori",
          "australian",
          "movi",
          "aw",
          "australian",
          "stori",
          "yet",
          "seem",
          "like",
          "set",
          "america",
          "also",
          "ned",
          "australian",
          "yet",
          "irish",
          "accentit",
          "worst",
          "film",
          "seen",
          "long",
          "time"
         ],
         [
          "ned",
          "akelly",
          "important",
          "story",
          "australian",
          "movie",
          "awful",
          "australian",
          "story",
          "yet",
          "seems",
          "like",
          "set",
          "america",
          "also",
          "ned",
          "australian",
          "yet",
          "irish",
          "accentit",
          "worst",
          "film",
          "seen",
          "long",
          "time"
         ],
         247,
         159,
         25,
         25,
         25,
         247,
         159,
         25,
         25,
         25
        ],
        [
         "Protocol is an implausible movie whose only saving grace is that it stars Goldie Hawn along with a good cast of supporting actors. The story revolves around a ditzy cocktail waitress who becomes famous after inadvertently saving the life of an Arab dignitary. The story goes downhill halfway through the movie and Goldie's charm just doesn't save this movie. Unless you are a Goldie Hawn fan don't go out of your way to see this film.",
         0,
         "protocol implausible movie whose saving grace stars goldie hawn along good cast supporting actors story revolves around ditzy cocktail waitress becomes famous inadvertently saving life arab dignitary story goes downhill halfway movie goldies charm doesnt save movie unless goldie hawn fan dont go way see film",
         [
          "protocol",
          "implausible",
          "movie",
          "whose",
          "saving",
          "grace",
          "stars",
          "goldie",
          "hawn",
          "along",
          "good",
          "cast",
          "supporting",
          "actors",
          "story",
          "revolves",
          "around",
          "ditzy",
          "cocktail",
          "waitress",
          "becomes",
          "famous",
          "inadvertently",
          "saving",
          "life",
          "arab",
          "dignitary",
          "story",
          "goes",
          "downhill",
          "halfway",
          "movie",
          "goldies",
          "charm",
          "doesnt",
          "save",
          "movie",
          "unless",
          "goldie",
          "hawn",
          "fan",
          "dont",
          "go",
          "way",
          "see",
          "film"
         ],
         [
          "protocol",
          "implaus",
          "movi",
          "whose",
          "save",
          "grace",
          "star",
          "goldi",
          "hawn",
          "along",
          "good",
          "cast",
          "support",
          "actor",
          "stori",
          "revolv",
          "around",
          "ditzi",
          "cocktail",
          "waitress",
          "becom",
          "famou",
          "inadvert",
          "save",
          "life",
          "arab",
          "dignitari",
          "stori",
          "goe",
          "downhil",
          "halfway",
          "movi",
          "goldi",
          "charm",
          "doesnt",
          "save",
          "movi",
          "unless",
          "goldi",
          "hawn",
          "fan",
          "dont",
          "go",
          "way",
          "see",
          "film"
         ],
         [
          "protocol",
          "implausible",
          "movie",
          "whose",
          "saving",
          "grace",
          "star",
          "goldie",
          "hawn",
          "along",
          "good",
          "cast",
          "supporting",
          "actor",
          "story",
          "revolves",
          "around",
          "ditzy",
          "cocktail",
          "waitress",
          "becomes",
          "famous",
          "inadvertently",
          "saving",
          "life",
          "arab",
          "dignitary",
          "story",
          "go",
          "downhill",
          "halfway",
          "movie",
          "goldies",
          "charm",
          "doesnt",
          "save",
          "movie",
          "unless",
          "goldie",
          "hawn",
          "fan",
          "dont",
          "go",
          "way",
          "see",
          "film"
         ],
         434,
         309,
         46,
         46,
         46,
         434,
         309,
         46,
         46,
         46
        ],
        [
         "Outlandish premise that rates low on plausibility and unfortunately also struggles feebly to raise laughs or interest. Only Hawn's well-known charm allows it to skate by on very thin ice. Goldie's gotta be a contender for an actress who's done so much in her career with very little quality material at her disposal...<br /><br />",
         0,
         "outlandish premise rates low plausibility unfortunately also struggles feebly raise laughs interest hawns wellknown charm allows skate thin ice goldies gotta contender actress whos done much career little quality material disposalbr br",
         [
          "outlandish",
          "premise",
          "rates",
          "low",
          "plausibility",
          "unfortunately",
          "also",
          "struggles",
          "feebly",
          "raise",
          "laughs",
          "interest",
          "hawns",
          "wellknown",
          "charm",
          "allows",
          "skate",
          "thin",
          "ice",
          "goldies",
          "gotta",
          "contender",
          "actress",
          "whos",
          "done",
          "much",
          "career",
          "little",
          "quality",
          "material",
          "disposalbr",
          "br"
         ],
         [
          "outlandish",
          "premis",
          "rate",
          "low",
          "plausibl",
          "unfortun",
          "also",
          "struggl",
          "feebli",
          "rais",
          "laugh",
          "interest",
          "hawn",
          "wellknown",
          "charm",
          "allow",
          "skate",
          "thin",
          "ice",
          "goldi",
          "gotta",
          "contend",
          "actress",
          "who",
          "done",
          "much",
          "career",
          "littl",
          "qualiti",
          "materi",
          "disposalbr",
          "br"
         ],
         [
          "outlandish",
          "premise",
          "rate",
          "low",
          "plausibility",
          "unfortunately",
          "also",
          "struggle",
          "feebly",
          "raise",
          "laugh",
          "interest",
          "hawns",
          "wellknown",
          "charm",
          "allows",
          "skate",
          "thin",
          "ice",
          "goldies",
          "gotta",
          "contender",
          "actress",
          "who",
          "done",
          "much",
          "career",
          "little",
          "quality",
          "material",
          "disposalbr",
          "br"
         ],
         330,
         235,
         32,
         32,
         32,
         330,
         235,
         32,
         32,
         32
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "text",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "label",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "cleaned_text",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "tokens",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "stemmed_tokens",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "lemmatized_tokens",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "review_length",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "cleaned_text_length",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "tokens_length",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "stemmed_tokens_length",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "lemmatized_tokens_length",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "text_count",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "cleaned_text_count",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "tokens_count",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "stemmed_tokens_count",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "lemmatized_tokens_count",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Execute a SQL query on the \"imdb_prepared\" temporary view to select rows where\n",
    "# review_length is less than 500, and limit the result to 5 rows\n",
    "sql_result = spark.sql(\"SELECT * FROM imdb_prepared WHERE review_length < 500 LIMIT 5\")\n",
    "\n",
    "# Display the result using the display function (assuming display is defined)\n",
    "display(sql_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8026fda8-dbfe-4c35-9183-49d8ebad4bde",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.6 Analysis and Visualizations through SQL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "570ed4cf-0624-42e1-ae65-fe147b83c00c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>text</th><th>label</th><th>cleaned_text</th><th>tokens</th><th>stemmed_tokens</th><th>lemmatized_tokens</th><th>review_length</th><th>cleaned_text_length</th><th>tokens_length</th><th>stemmed_tokens_length</th><th>lemmatized_tokens_length</th><th>text_count</th><th>cleaned_text_count</th><th>tokens_count</th><th>stemmed_tokens_count</th><th>lemmatized_tokens_count</th></tr></thead><tbody><tr><td>My interest in Dorothy Stratten caused me to purchase this video. Although it had great actors/actresses, there were just too many subplots going on to retain interest. Plus it just wasn't that interesting. Dialogue was stiff and confusing and the story just flipped around too much to be believable. I was pretty disappointed in what I believe was one of Audrey Hepburn's last movies. I'll always love John Ritter best in slapstick. He was just too pathetic here.</td><td>0</td><td>interest dorothy stratten caused purchase video although great actorsactresses many subplots going retain interest plus wasnt interesting dialogue stiff confusing story flipped around much believable pretty disappointed believe one audrey hepburns last movies ill always love john ritter best slapstick pathetic</td><td>List(interest, dorothy, stratten, caused, purchase, video, although, great, actorsactresses, many, subplots, going, retain, interest, plus, wasnt, interesting, dialogue, stiff, confusing, story, flipped, around, much, believable, pretty, disappointed, believe, one, audrey, hepburns, last, movies, ill, always, love, john, ritter, best, slapstick, pathetic)</td><td>List(interest, dorothi, stratten, caus, purchas, video, although, great, actorsactress, mani, subplot, go, retain, interest, plu, wasnt, interest, dialogu, stiff, confus, stori, flip, around, much, believ, pretti, disappoint, believ, one, audrey, hepburn, last, movi, ill, alway, love, john, ritter, best, slapstick, pathet)</td><td>List(interest, dorothy, stratten, caused, purchase, video, although, great, actorsactresses, many, subplots, going, retain, interest, plus, wasnt, interesting, dialogue, stiff, confusing, story, flipped, around, much, believable, pretty, disappointed, believe, one, audrey, hepburn, last, movie, ill, always, love, john, ritter, best, slapstick, pathetic)</td><td>464</td><td>311</td><td>41</td><td>41</td><td>41</td><td>464</td><td>311</td><td>41</td><td>41</td><td>41</td></tr><tr><td>I think I will make a movie next weekend. Oh wait, I'm working..oh I'm sure I can fit it in. It looks like whoever made this film fit it in. I hope the makers of this crap have day jobs because this film sucked!!! It looks like someones home movie and I don't think more than $100 was spent making it!!! Total crap!!! Who let's this stuff be released?!?!?!</td><td>0</td><td>think make movie next weekend oh wait im workingoh im sure fit looks like whoever made film fit hope makers crap day jobs film sucked looks like someones home movie dont think spent making total crap lets stuff released</td><td>List(think, make, movie, next, weekend, oh, wait, im, workingoh, im, sure, fit, looks, like, whoever, made, film, fit, hope, makers, crap, day, jobs, film, sucked, looks, like, someones, home, movie, dont, think, spent, making, total, crap, lets, stuff, released)</td><td>List(think, make, movi, next, weekend, oh, wait, im, workingoh, im, sure, fit, look, like, whoever, made, film, fit, hope, maker, crap, day, job, film, suck, look, like, someon, home, movi, dont, think, spent, make, total, crap, let, stuff, releas)</td><td>List(think, make, movie, next, weekend, oh, wait, im, workingoh, im, sure, fit, look, like, whoever, made, film, fit, hope, maker, crap, day, job, film, sucked, look, like, someone, home, movie, dont, think, spent, making, total, crap, let, stuff, released)</td><td>356</td><td>219</td><td>39</td><td>39</td><td>39</td><td>356</td><td>219</td><td>39</td><td>39</td><td>39</td></tr><tr><td>Ned aKelly is such an important story to Australians but this movie is awful. It's an Australian story yet it seems like it was set in America. Also Ned was an Australian yet he has an Irish accent...it is the worst film I have seen in a long time</td><td>0</td><td>ned akelly important story australians movie awful australian story yet seems like set america also ned australian yet irish accentit worst film seen long time</td><td>List(ned, akelly, important, story, australians, movie, awful, australian, story, yet, seems, like, set, america, also, ned, australian, yet, irish, accentit, worst, film, seen, long, time)</td><td>List(ned, akelli, import, stori, australian, movi, aw, australian, stori, yet, seem, like, set, america, also, ned, australian, yet, irish, accentit, worst, film, seen, long, time)</td><td>List(ned, akelly, important, story, australian, movie, awful, australian, story, yet, seems, like, set, america, also, ned, australian, yet, irish, accentit, worst, film, seen, long, time)</td><td>247</td><td>159</td><td>25</td><td>25</td><td>25</td><td>247</td><td>159</td><td>25</td><td>25</td><td>25</td></tr><tr><td>Protocol is an implausible movie whose only saving grace is that it stars Goldie Hawn along with a good cast of supporting actors. The story revolves around a ditzy cocktail waitress who becomes famous after inadvertently saving the life of an Arab dignitary. The story goes downhill halfway through the movie and Goldie's charm just doesn't save this movie. Unless you are a Goldie Hawn fan don't go out of your way to see this film.</td><td>0</td><td>protocol implausible movie whose saving grace stars goldie hawn along good cast supporting actors story revolves around ditzy cocktail waitress becomes famous inadvertently saving life arab dignitary story goes downhill halfway movie goldies charm doesnt save movie unless goldie hawn fan dont go way see film</td><td>List(protocol, implausible, movie, whose, saving, grace, stars, goldie, hawn, along, good, cast, supporting, actors, story, revolves, around, ditzy, cocktail, waitress, becomes, famous, inadvertently, saving, life, arab, dignitary, story, goes, downhill, halfway, movie, goldies, charm, doesnt, save, movie, unless, goldie, hawn, fan, dont, go, way, see, film)</td><td>List(protocol, implaus, movi, whose, save, grace, star, goldi, hawn, along, good, cast, support, actor, stori, revolv, around, ditzi, cocktail, waitress, becom, famou, inadvert, save, life, arab, dignitari, stori, goe, downhil, halfway, movi, goldi, charm, doesnt, save, movi, unless, goldi, hawn, fan, dont, go, way, see, film)</td><td>List(protocol, implausible, movie, whose, saving, grace, star, goldie, hawn, along, good, cast, supporting, actor, story, revolves, around, ditzy, cocktail, waitress, becomes, famous, inadvertently, saving, life, arab, dignitary, story, go, downhill, halfway, movie, goldies, charm, doesnt, save, movie, unless, goldie, hawn, fan, dont, go, way, see, film)</td><td>434</td><td>309</td><td>46</td><td>46</td><td>46</td><td>434</td><td>309</td><td>46</td><td>46</td><td>46</td></tr><tr><td>Outlandish premise that rates low on plausibility and unfortunately also struggles feebly to raise laughs or interest. Only Hawn's well-known charm allows it to skate by on very thin ice. Goldie's gotta be a contender for an actress who's done so much in her career with very little quality material at her disposal...<br /><br /></td><td>0</td><td>outlandish premise rates low plausibility unfortunately also struggles feebly raise laughs interest hawns wellknown charm allows skate thin ice goldies gotta contender actress whos done much career little quality material disposalbr br</td><td>List(outlandish, premise, rates, low, plausibility, unfortunately, also, struggles, feebly, raise, laughs, interest, hawns, wellknown, charm, allows, skate, thin, ice, goldies, gotta, contender, actress, whos, done, much, career, little, quality, material, disposalbr, br)</td><td>List(outlandish, premis, rate, low, plausibl, unfortun, also, struggl, feebli, rais, laugh, interest, hawn, wellknown, charm, allow, skate, thin, ice, goldi, gotta, contend, actress, who, done, much, career, littl, qualiti, materi, disposalbr, br)</td><td>List(outlandish, premise, rate, low, plausibility, unfortunately, also, struggle, feebly, raise, laugh, interest, hawns, wellknown, charm, allows, skate, thin, ice, goldies, gotta, contender, actress, who, done, much, career, little, quality, material, disposalbr, br)</td><td>330</td><td>235</td><td>32</td><td>32</td><td>32</td><td>330</td><td>235</td><td>32</td><td>32</td><td>32</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "My interest in Dorothy Stratten caused me to purchase this video. Although it had great actors/actresses, there were just too many subplots going on to retain interest. Plus it just wasn't that interesting. Dialogue was stiff and confusing and the story just flipped around too much to be believable. I was pretty disappointed in what I believe was one of Audrey Hepburn's last movies. I'll always love John Ritter best in slapstick. He was just too pathetic here.",
         0,
         "interest dorothy stratten caused purchase video although great actorsactresses many subplots going retain interest plus wasnt interesting dialogue stiff confusing story flipped around much believable pretty disappointed believe one audrey hepburns last movies ill always love john ritter best slapstick pathetic",
         [
          "interest",
          "dorothy",
          "stratten",
          "caused",
          "purchase",
          "video",
          "although",
          "great",
          "actorsactresses",
          "many",
          "subplots",
          "going",
          "retain",
          "interest",
          "plus",
          "wasnt",
          "interesting",
          "dialogue",
          "stiff",
          "confusing",
          "story",
          "flipped",
          "around",
          "much",
          "believable",
          "pretty",
          "disappointed",
          "believe",
          "one",
          "audrey",
          "hepburns",
          "last",
          "movies",
          "ill",
          "always",
          "love",
          "john",
          "ritter",
          "best",
          "slapstick",
          "pathetic"
         ],
         [
          "interest",
          "dorothi",
          "stratten",
          "caus",
          "purchas",
          "video",
          "although",
          "great",
          "actorsactress",
          "mani",
          "subplot",
          "go",
          "retain",
          "interest",
          "plu",
          "wasnt",
          "interest",
          "dialogu",
          "stiff",
          "confus",
          "stori",
          "flip",
          "around",
          "much",
          "believ",
          "pretti",
          "disappoint",
          "believ",
          "one",
          "audrey",
          "hepburn",
          "last",
          "movi",
          "ill",
          "alway",
          "love",
          "john",
          "ritter",
          "best",
          "slapstick",
          "pathet"
         ],
         [
          "interest",
          "dorothy",
          "stratten",
          "caused",
          "purchase",
          "video",
          "although",
          "great",
          "actorsactresses",
          "many",
          "subplots",
          "going",
          "retain",
          "interest",
          "plus",
          "wasnt",
          "interesting",
          "dialogue",
          "stiff",
          "confusing",
          "story",
          "flipped",
          "around",
          "much",
          "believable",
          "pretty",
          "disappointed",
          "believe",
          "one",
          "audrey",
          "hepburn",
          "last",
          "movie",
          "ill",
          "always",
          "love",
          "john",
          "ritter",
          "best",
          "slapstick",
          "pathetic"
         ],
         464,
         311,
         41,
         41,
         41,
         464,
         311,
         41,
         41,
         41
        ],
        [
         "I think I will make a movie next weekend. Oh wait, I'm working..oh I'm sure I can fit it in. It looks like whoever made this film fit it in. I hope the makers of this crap have day jobs because this film sucked!!! It looks like someones home movie and I don't think more than $100 was spent making it!!! Total crap!!! Who let's this stuff be released?!?!?!",
         0,
         "think make movie next weekend oh wait im workingoh im sure fit looks like whoever made film fit hope makers crap day jobs film sucked looks like someones home movie dont think spent making total crap lets stuff released",
         [
          "think",
          "make",
          "movie",
          "next",
          "weekend",
          "oh",
          "wait",
          "im",
          "workingoh",
          "im",
          "sure",
          "fit",
          "looks",
          "like",
          "whoever",
          "made",
          "film",
          "fit",
          "hope",
          "makers",
          "crap",
          "day",
          "jobs",
          "film",
          "sucked",
          "looks",
          "like",
          "someones",
          "home",
          "movie",
          "dont",
          "think",
          "spent",
          "making",
          "total",
          "crap",
          "lets",
          "stuff",
          "released"
         ],
         [
          "think",
          "make",
          "movi",
          "next",
          "weekend",
          "oh",
          "wait",
          "im",
          "workingoh",
          "im",
          "sure",
          "fit",
          "look",
          "like",
          "whoever",
          "made",
          "film",
          "fit",
          "hope",
          "maker",
          "crap",
          "day",
          "job",
          "film",
          "suck",
          "look",
          "like",
          "someon",
          "home",
          "movi",
          "dont",
          "think",
          "spent",
          "make",
          "total",
          "crap",
          "let",
          "stuff",
          "releas"
         ],
         [
          "think",
          "make",
          "movie",
          "next",
          "weekend",
          "oh",
          "wait",
          "im",
          "workingoh",
          "im",
          "sure",
          "fit",
          "look",
          "like",
          "whoever",
          "made",
          "film",
          "fit",
          "hope",
          "maker",
          "crap",
          "day",
          "job",
          "film",
          "sucked",
          "look",
          "like",
          "someone",
          "home",
          "movie",
          "dont",
          "think",
          "spent",
          "making",
          "total",
          "crap",
          "let",
          "stuff",
          "released"
         ],
         356,
         219,
         39,
         39,
         39,
         356,
         219,
         39,
         39,
         39
        ],
        [
         "Ned aKelly is such an important story to Australians but this movie is awful. It's an Australian story yet it seems like it was set in America. Also Ned was an Australian yet he has an Irish accent...it is the worst film I have seen in a long time",
         0,
         "ned akelly important story australians movie awful australian story yet seems like set america also ned australian yet irish accentit worst film seen long time",
         [
          "ned",
          "akelly",
          "important",
          "story",
          "australians",
          "movie",
          "awful",
          "australian",
          "story",
          "yet",
          "seems",
          "like",
          "set",
          "america",
          "also",
          "ned",
          "australian",
          "yet",
          "irish",
          "accentit",
          "worst",
          "film",
          "seen",
          "long",
          "time"
         ],
         [
          "ned",
          "akelli",
          "import",
          "stori",
          "australian",
          "movi",
          "aw",
          "australian",
          "stori",
          "yet",
          "seem",
          "like",
          "set",
          "america",
          "also",
          "ned",
          "australian",
          "yet",
          "irish",
          "accentit",
          "worst",
          "film",
          "seen",
          "long",
          "time"
         ],
         [
          "ned",
          "akelly",
          "important",
          "story",
          "australian",
          "movie",
          "awful",
          "australian",
          "story",
          "yet",
          "seems",
          "like",
          "set",
          "america",
          "also",
          "ned",
          "australian",
          "yet",
          "irish",
          "accentit",
          "worst",
          "film",
          "seen",
          "long",
          "time"
         ],
         247,
         159,
         25,
         25,
         25,
         247,
         159,
         25,
         25,
         25
        ],
        [
         "Protocol is an implausible movie whose only saving grace is that it stars Goldie Hawn along with a good cast of supporting actors. The story revolves around a ditzy cocktail waitress who becomes famous after inadvertently saving the life of an Arab dignitary. The story goes downhill halfway through the movie and Goldie's charm just doesn't save this movie. Unless you are a Goldie Hawn fan don't go out of your way to see this film.",
         0,
         "protocol implausible movie whose saving grace stars goldie hawn along good cast supporting actors story revolves around ditzy cocktail waitress becomes famous inadvertently saving life arab dignitary story goes downhill halfway movie goldies charm doesnt save movie unless goldie hawn fan dont go way see film",
         [
          "protocol",
          "implausible",
          "movie",
          "whose",
          "saving",
          "grace",
          "stars",
          "goldie",
          "hawn",
          "along",
          "good",
          "cast",
          "supporting",
          "actors",
          "story",
          "revolves",
          "around",
          "ditzy",
          "cocktail",
          "waitress",
          "becomes",
          "famous",
          "inadvertently",
          "saving",
          "life",
          "arab",
          "dignitary",
          "story",
          "goes",
          "downhill",
          "halfway",
          "movie",
          "goldies",
          "charm",
          "doesnt",
          "save",
          "movie",
          "unless",
          "goldie",
          "hawn",
          "fan",
          "dont",
          "go",
          "way",
          "see",
          "film"
         ],
         [
          "protocol",
          "implaus",
          "movi",
          "whose",
          "save",
          "grace",
          "star",
          "goldi",
          "hawn",
          "along",
          "good",
          "cast",
          "support",
          "actor",
          "stori",
          "revolv",
          "around",
          "ditzi",
          "cocktail",
          "waitress",
          "becom",
          "famou",
          "inadvert",
          "save",
          "life",
          "arab",
          "dignitari",
          "stori",
          "goe",
          "downhil",
          "halfway",
          "movi",
          "goldi",
          "charm",
          "doesnt",
          "save",
          "movi",
          "unless",
          "goldi",
          "hawn",
          "fan",
          "dont",
          "go",
          "way",
          "see",
          "film"
         ],
         [
          "protocol",
          "implausible",
          "movie",
          "whose",
          "saving",
          "grace",
          "star",
          "goldie",
          "hawn",
          "along",
          "good",
          "cast",
          "supporting",
          "actor",
          "story",
          "revolves",
          "around",
          "ditzy",
          "cocktail",
          "waitress",
          "becomes",
          "famous",
          "inadvertently",
          "saving",
          "life",
          "arab",
          "dignitary",
          "story",
          "go",
          "downhill",
          "halfway",
          "movie",
          "goldies",
          "charm",
          "doesnt",
          "save",
          "movie",
          "unless",
          "goldie",
          "hawn",
          "fan",
          "dont",
          "go",
          "way",
          "see",
          "film"
         ],
         434,
         309,
         46,
         46,
         46,
         434,
         309,
         46,
         46,
         46
        ],
        [
         "Outlandish premise that rates low on plausibility and unfortunately also struggles feebly to raise laughs or interest. Only Hawn's well-known charm allows it to skate by on very thin ice. Goldie's gotta be a contender for an actress who's done so much in her career with very little quality material at her disposal...<br /><br />",
         0,
         "outlandish premise rates low plausibility unfortunately also struggles feebly raise laughs interest hawns wellknown charm allows skate thin ice goldies gotta contender actress whos done much career little quality material disposalbr br",
         [
          "outlandish",
          "premise",
          "rates",
          "low",
          "plausibility",
          "unfortunately",
          "also",
          "struggles",
          "feebly",
          "raise",
          "laughs",
          "interest",
          "hawns",
          "wellknown",
          "charm",
          "allows",
          "skate",
          "thin",
          "ice",
          "goldies",
          "gotta",
          "contender",
          "actress",
          "whos",
          "done",
          "much",
          "career",
          "little",
          "quality",
          "material",
          "disposalbr",
          "br"
         ],
         [
          "outlandish",
          "premis",
          "rate",
          "low",
          "plausibl",
          "unfortun",
          "also",
          "struggl",
          "feebli",
          "rais",
          "laugh",
          "interest",
          "hawn",
          "wellknown",
          "charm",
          "allow",
          "skate",
          "thin",
          "ice",
          "goldi",
          "gotta",
          "contend",
          "actress",
          "who",
          "done",
          "much",
          "career",
          "littl",
          "qualiti",
          "materi",
          "disposalbr",
          "br"
         ],
         [
          "outlandish",
          "premise",
          "rate",
          "low",
          "plausibility",
          "unfortunately",
          "also",
          "struggle",
          "feebly",
          "raise",
          "laugh",
          "interest",
          "hawns",
          "wellknown",
          "charm",
          "allows",
          "skate",
          "thin",
          "ice",
          "goldies",
          "gotta",
          "contender",
          "actress",
          "who",
          "done",
          "much",
          "career",
          "little",
          "quality",
          "material",
          "disposalbr",
          "br"
         ],
         330,
         235,
         32,
         32,
         32,
         330,
         235,
         32,
         32,
         32
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "text",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "label",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "cleaned_text",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "tokens",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "stemmed_tokens",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "lemmatized_tokens",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "review_length",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "cleaned_text_length",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "tokens_length",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "stemmed_tokens_length",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "lemmatized_tokens_length",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "text_count",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "cleaned_text_count",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "tokens_count",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "stemmed_tokens_count",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "lemmatized_tokens_count",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    " \n",
    "-- Refresh the \"imdb_prepared\" table/view to ensure it reflects recent changes\n",
    "REFRESH TABLE imdb_prepared;\n",
    "\n",
    "-- Select up to 5 rows from the \"imdb_prepared\" table/view where review_length is less than 500\n",
    "SELECT * FROM imdb_prepared WHERE review_length < 500 LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0f7a105-eb1f-4877-883b-6f2d1bcff58f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "### Pandas\n",
    "- **Use Cases**: Small to medium-sized datasets, local data analysis, quick prototyping.\n",
    "- **Advantages**: Easy to use, rich functionality, excellent for in-memory operations.\n",
    "- **Disadvantages**: Not suitable for very large datasets due to memory constraints.\n",
    "\n",
    "### PySpark\n",
    "- **Use Cases**: Large datasets, distributed data processing, big data analytics.\n",
    "- **Advantages**: Scalable, can handle large datasets, integrates well with Hadoop.\n",
    "- **Disadvantages**: More complex than Pandas, requires a Spark cluster.\n",
    "\n",
    "### SQL\n",
    "- **Use Cases**: Data querying, reporting, integration with BI tools.\n",
    "- **Advantages**: Familiarity for users with SQL background, powerful for data retrieval and manipulation.\n",
    "- **Disadvantages**: Limited to SQL operations, may require additional steps for complex data manipulations."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 319656315199568,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Data Processing in databricks",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
